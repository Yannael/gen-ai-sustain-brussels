# SustAIn.Brussels training: ChatGPT and next-generation AI assistants

![slide1](images/slide1.png)

This repository contains the training material for the [SustAIn.Brussels training track on ChatGPT and next-generation assistants](https://www.sustain.brussels/fr_BE/event/chatgpt-next-generation-assistants-training-track-108/register). The track took place between the 2nd of April 2025 and the 4th of April 2025, at [FARI](https://www.fari.brussels/).


# Part 1: Non-technical introduction to generative AI

Full day (6 hours). Instructor: [Yann-Aël Le Borgne](https://www.linkedin.com/in/yannaelb/). The slides are available [in PDF format](https://github.com/Yannael/gen-ai-sustain-brussels/tree/main/Part_1_Intro_ChatGPT_AI_Assistants) or as [Google slides](https://docs.google.com/presentation/d/1x82pTUJd5nogycmzaOZIUKLYJLg7_PSJ).

The day was divided in five main parts:

- 1h30: Examples of generative AI applications
- 1h30: Machine learning, image recognition and next-word prediction
- 1h: LLM training, technical limits and mitigations
- 1h: Ethical concerns: Biases, privacy and environmental impacts
- 1h: LLM ecosystem: Proprietary and open-source solutions


# Part 2: Hands-on session - Using the OpenAI API

Half-day (3 hours). Instructor: [Olivier Caelen](https://www.linkedin.com/in/oliviercaelen/). The notebooks are [available here](https://github.com/Yannael/gen-ai-sustain-brussels/tree/main/Part_2_OpenAI_API).

Examples are mostly taken from Olivier's book "[Developing Apps with GPT-4 and ChatGPT](https://www.oreilly.com/library/view/developing-apps-with/9781098152475/)". 

![oreilly](images/oreilly-book.jpeg)

The session covered:

-  "Hello world": Connect to the OpenAI API and get responses from an OpenAI model [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/Yannael/gen-ai-sustain-brussels/blob/main/Part_2_OpenAI_API/1_HelloWorld.ipynb)
-  Forcing GPT to return a JSON output [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/Yannael/gen-ai-sustain-brussels/blob/main/Part_2_OpenAI_API/2_JSON.ipynb)
-  How to analyse images with the vision API [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/Yannael/gen-ai-sustain-brussels/blob/main/Part_2_OpenAI_API/3_Vision.ipynb)
-  How to generate image with DALL-E 3 [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/Yannael/gen-ai-sustain-brussels/blob/main/Part_2_OpenAI_API/4_DALL-E_3.ipynb)
-  Converting text to speech and speech to text [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/Yannael/gen-ai-sustain-brussels/blob/main/Part_2_OpenAI_API/5_Audio.ipynb)


# Part 3: Hands-on session - Using open-source models with Hugging Face

Half-day (3 hours). Instructor: [Yann-Aël Le Borgne](https://www.linkedin.com/in/yannaelb/). The notebooks are [available here](https://github.com/Yannael/gen-ai-sustain-brussels/tree/main/Part_3_HuggingFace_Gradio).

Examples are mostly taken from [Hugging Face online course on large language models](https://huggingface.co/learn/llm-course/chapter1/1?fw=pt).

<img src="https://github.com/Yannael/gen-ai-sustain-brussels/blob/main/images/huggingface_spaces.png?raw=true" width="600px"/>


The session covered:

- Text generation with open-source models (such as GPT2) using the Hugging Face transformers library [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/Yannael/gen-ai-sustain-brussels/blob/main/Part_3_HuggingFace_Gradio/1_Transformers.ipynb)
- Building a web app with Gradio [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/Yannael/gen-ai-sustain-brussels/blob/main/Part_3_HuggingFace_Gradio/2_Gradio.ipynb)
- Making a Gradio web app predict text with the transformers library, or OpenAI API [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/Yannael/gen-ai-sustain-brussels/blob/main/Part_3_HuggingFace_Gradio/1_Transformers.ipynb)
- Deploying the web app on Hugging Face spaces for free [<img align="center" src="https://colab.research.google.com/assets/colab-badge.svg" />](https://colab.research.google.com/github/Yannael/gen-ai-sustain-brussels/blob/main/Part_3_HuggingFace_Gradio/1_Transformers.ipynb)

