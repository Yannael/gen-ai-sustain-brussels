{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_W11d7IeYX1"
      },
      "source": [
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neVh56GWjDZJ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeNrqZafeQQO",
        "outputId": "f2df073a-40f2-4e1e-8dac-2803d701757d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.69.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAc8z7eSNhEr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kr1spfRVeX_v"
      },
      "source": [
        "\n",
        "# Connecting to the OpenAI API\n",
        "This line creates a client that will let us send messages to GPT and get responses back.\n",
        "\n",
        "We use our API key to tell OpenAI who we are and that we are allowed to use the service.\n",
        "\n",
        "\n",
        "** TO DO: show who to get an OpenAI API key **\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_mnz15JfV-w"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(api_key=\"YOUR_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1UFtOcyj90y"
      },
      "source": [
        "⚠️ **Important**: Normally, **it's a very bad practice to put an API key directly in the notebook or in any source code**.\n",
        "A better and safer way is to store the key in an external file (like a .env file or a config file) and load it from there in your application.\n",
        "\n",
        "This key will be revoked at the end of the lecture, so it will not be possible to reuse it later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCCfq3MyltkU"
      },
      "source": [
        "# Asking GPT to Answer a Question\n",
        "\n",
        "Here, we send a message to GPT and ask it to generate a response:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OOe1dEk-grAT"
      },
      "outputs": [],
      "source": [
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4o\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Compose a short poem that explains the concept of recursion in programming.\"}\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlQ3U7u3mSJC"
      },
      "source": [
        "\n",
        "\n",
        "* The  `\n",
        "model=\"gpt-4o\"\n",
        "` tell OpenAI which version of ChatGPT we want to use.\n",
        "Different models have different abilities, speed, and cost.\n",
        "https://platform.openai.com/docs/models\n",
        "*   The `messages` parameter is a list of messages that create the conversation between the user and ChatGPT.\n",
        "\n",
        "    Each message has:\n",
        "    - a **role**: who is speaking (`system`, `user`, or `assistant`)\n",
        "    - a **content**: the text of the message\n",
        "\n",
        "    Roles explained:\n",
        "    - **system**: sets the behavior or personality of ChatGPT.\n",
        "    - **user**: the question or instruction from the user.\n",
        "    - **assistant**: (optional) can include past replies from ChatGPT if you want to continue a longer conversation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jRXS3Rhrofuy"
      },
      "source": [
        "# Getting the Response from ChatGPT\n",
        "\n",
        "After sending our request, we want to see the reply from ChatGPT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIKn17Crg1NA",
        "outputId": "4d8b7b26-59aa-443d-cd98-58d02e36246f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the realm of code where logic takes flight,  \n",
            "Lives a concept so clever, a recursive delight.  \n",
            "Where functions call themselves, with purpose and grace,  \n",
            "In a dance of procedures, they elegantly trace.  \n",
            "\n",
            "Imagine a function, a clever little sprite,  \n",
            "It whispers to itself, in the soft moonlight.  \n",
            "\"To solve this grand problem, I must first concede,  \n",
            "Break it down to smaller tasks, with precision indeed.\"\n",
            "\n",
            "Like Russian dolls nestled, one within another,  \n",
            "Each call peels a layer, to uncover its brother.  \n",
            "For every grand problem begins at a peak,  \n",
            "A call to the depths, where the answers we'll seek.  \n",
            "\n",
            "With each self-invocation, a slice of the whole,  \n",
            "Creeping ever closer to the base case goal.  \n",
            "Once the simplest of puzzles is finally undone,  \n",
            "The calls retrace their steps, their mission all won.  \n",
            "\n",
            "Oh recursion, you mirror of endless reflection,  \n",
            "A loop through dimensions, a path to perfection.  \n",
            "In the heart of the code, your pattern does lie,  \n",
            "A fractal of logic, reaching to the sky.\n"
          ]
        }
      ],
      "source": [
        "print(completion.choices[0].message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUdmLJm2otBL"
      },
      "source": [
        "This line prints the text of the response generated by the model.\n",
        "\n",
        "Here's what it means:\n",
        "\n",
        "\n",
        "* `completion.choices` is a list of possible replies (usually just one).\n",
        "* `[0]` means we take the first (and only) reply.\n",
        "* `.message.content` gives us the actual text of the response."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoUZj_l5p6fq"
      },
      "source": [
        "# ChatGPT API is Stateless\n",
        "\n",
        "The ChatGPT API is **stateless**, which means it does **not remember** previous conversations by itself.\n",
        "\n",
        "If you want the model to remember what was said before, **you must include the full conversation** in the `messages` parameter each time.\n",
        "\n",
        "So you are responsible for building and updating the conversation history like this:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLpMoKmMqDEM"
      },
      "outputs": [],
      "source": [
        "messages = [\n",
        "  {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "  {\"role\": \"user\", \"content\": \"What is a function in Python?\"},\n",
        "  {\"role\": \"assistant\", \"content\": \"A function is a block of code...\"},\n",
        "  {\"role\": \"user\", \"content\": \"Can you give me an example?\"}\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX-TDF1MsksD"
      },
      "source": [
        "# ✏️ Practice Questions\n",
        "1. **Change the model:**  \n",
        "   In the code where we ask ChatGPT a question, change the model from `\"gpt-4o\"` to `\"gpt-4.5-preview\"`.  \n",
        "   👉 Run the cell again and see if the answer changes.\n",
        "2. **Ask your own question:**  \n",
        "   Modify the user message to ask something different (for example:  \n",
        "   \"*Can you give me a simple recipe for a cake?*\")  \n",
        "   👉 Run the code and read the new response from ChatGPT.\n",
        "3. **Be creative:**  \n",
        "    Change the `system` message to something fun, like:  \n",
        "    \"*You are a pirate who speaks only in rhymes.*\"\n",
        "\n",
        "    Then ask a question and see how the response changes!\n",
        "4. **Build a full conversation history (bonus):**  \n",
        "   Imagine you're building a cooking chatbot. You want the assistant to remember what was said earlier.\n",
        "\n",
        "   👉 Create a new `messages` list that contains **at least 4 messages**, like this:\n",
        "\n",
        "   - A `system` message that says: *\"You are a friendly chef who gives cooking tips.\"*  \n",
        "   - A `user` question: *\"What is the best way to cook pasta?\"*  \n",
        "   - An `assistant` reply (write a short answer yourself, just for context).  \n",
        "   - Another `user` follow-up: *\"Can I add olive oil to the water?\"*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
